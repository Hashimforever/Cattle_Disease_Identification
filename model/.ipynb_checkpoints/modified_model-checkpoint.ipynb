{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8110aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision.models import ResNet\n",
    "from ccsam_module import CCSAM\n",
    "from torch import nn\n",
    "from torchvision.models.inception import Inception3\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3e3315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ccsam): CCSAM(\n",
      "        (channel_attention): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (spatial_attention): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ccsam): CCSAM(\n",
      "        (channel_attention): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (spatial_attention): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ccsam): CCSAM(\n",
      "        (channel_attention): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (spatial_attention): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ccsam): CCSAM(\n",
      "        (channel_attention): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (spatial_attention): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ccsam): CCSAM(\n",
      "        (channel_attention): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (spatial_attention): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ccsam): CCSAM(\n",
      "        (channel_attention): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (spatial_attention): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ccsam): CCSAM(\n",
      "        (channel_attention): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (spatial_attention): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ccsam): CCSAM(\n",
      "        (channel_attention): ChannelAttention(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (spatial_attention): SpatialAttention(\n",
      "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None,\n",
    "                 *, reduction=16):\n",
    "        super(BasicBlock, self).__init__()\n",
    "       \n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.ccsam = CCSAM(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.ccsam(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CCSAMBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None,\n",
    "                 *, reduction=16):\n",
    "        super(CCSAMBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.ccsam = CCSAM(planes * 4, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.ccsam(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def resnet18_ccsam(num_classes=5):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 256)\n",
    "   \n",
    "    # Add a dropout layer with probability 0.5\n",
    "    model.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "   \n",
    "    # Add a new fully connected layer with 5 output classes and softmax activation\n",
    "    model.fc2 = nn.Linear(256, 5)\n",
    "    model.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "model=resnet18_ccsam(num_classes=5)\n",
    "#print(\"this model is Fine_tuned ResNet18 with Combination of channel Attention and Spatial Attention Mechanism\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5566b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIREE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HIREE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing_layer_Resnet18WithCCSAM(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (CCSAM): CCSAM(\n",
      "          (channel_attention): ChannelAttention(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "            (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (spatial_attention): SpatialAttention(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (CCSAM): CCSAM(\n",
      "          (channel_attention): ChannelAttention(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "            (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (spatial_attention): SpatialAttention(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (CCSAM): CCSAM(\n",
      "          (channel_attention): ChannelAttention(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "            (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (spatial_attention): SpatialAttention(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (CCSAM): CCSAM(\n",
      "          (channel_attention): ChannelAttention(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "            (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (spatial_attention): SpatialAttention(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (CCSAM): CCSAM(\n",
      "          (channel_attention): ChannelAttention(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (spatial_attention): SpatialAttention(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (CCSAM): CCSAM(\n",
      "          (channel_attention): ChannelAttention(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (spatial_attention): SpatialAttention(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (CCSAM): CCSAM(\n",
      "          (channel_attention): ChannelAttention(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (spatial_attention): SpatialAttention(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (CCSAM): CCSAM(\n",
      "          (channel_attention): ChannelAttention(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (spatial_attention): SpatialAttention(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (fc2): Linear(in_features=256, out_features=5, bias=True)\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CCSAMInception3(nn.Module):\n",
    "    def __init__(self, num_classes=5, aux_logits=True, transform_input=False):\n",
    "        super(CCSAMInception3, self).__init__()\n",
    "        model = Inception3(num_classes=num_classes, aux_logits=aux_logits,\n",
    "                           transform_input=transform_input)\n",
    "        model.Mixed_5b.add_module(\"CCSAM\", CCSAM(192))\n",
    "        model.Mixed_5c.add_module(\"CCSAM\", CCSAM(256))\n",
    "        model.Mixed_5d.add_module(\"CCSAM\", CCSAM(288))\n",
    "        model.Mixed_6a.add_module(\"CCSAM\", CCSAM(288))\n",
    "        model.Mixed_6b.add_module(\"CCSAM\", CCSAM(768))\n",
    "        model.Mixed_6c.add_module(\"CCSAM\", CCSAM(768))\n",
    "        model.Mixed_6d.add_module(\"CCSAM\", CCSAM(768))\n",
    "        model.Mixed_6e.add_module(\"CCSAM\", CCSAM(768))\n",
    "        if aux_logits:\n",
    "            model.AuxLogits.add_module(\"CCSAM\", CCSAM(768))\n",
    "        model.Mixed_7a.add_module(\"CCSAM\", CCSAM(768))\n",
    "        model.Mixed_7b.add_module(\"CCSAM\", CCSAM(1280))\n",
    "        model.Mixed_7c.add_module(\"CCSAM\", CCSAM(2048))\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, h, w = x.size()\n",
    "        if (h, w) != (299, 299):\n",
    "            raise ValueError(\"input size must be (299, 299)\")\n",
    "\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def ccsam_inception_v3(**kwargs):\n",
    "    return CCSAMInception3(**kwargs)\n",
    "#model=ccsam_inception_v3(num_classes=5)\n",
    "#print(\"this model is inception_v3 with Combination of channel Attention and Spatial Attention Mechanism\")\n",
    "#print(model)\n",
    "\n",
    "class Freezing_layer_Resnet18WithCCSAM(nn.Module):\n",
    "    def __init__(self, num_classes=5, pretrained=True):\n",
    "        super(Freezing_layer_Resnet18WithCCSAM, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=pretrained)\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'layer1' in name or 'layer2' in name or 'layer3' in name or 'layer4' in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.model.layer1[0].add_module(\"CCSAM\", CCSAM(64))\n",
    "        self.model.layer1[1].add_module(\"CCSAM\", CCSAM(64))\n",
    "        self.model.layer2[0].add_module(\"CCSAM\", CCSAM(128))\n",
    "        self.model.layer2[1].add_module(\"CCSAM\", CCSAM(128))\n",
    "        self.model.layer3[0].add_module(\"CCSAM\", CCSAM(256))\n",
    "        self.model.layer3[1].add_module(\"CCSAM\", CCSAM(256))\n",
    "        self.model.layer4[0].add_module(\"CCSAM\", CCSAM(512))\n",
    "        self.model.layer4[1].add_module(\"CCSAM\", CCSAM(512))\n",
    "\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, 256)\n",
    "        self.model.dropout = nn.Dropout(p=0.5)\n",
    "        self.model.fc2 = nn.Linear(256, num_classes)\n",
    "        self.model.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "def Freezing_layer_Resnet18WithCCSAM1(num_classes=5):\n",
    "    return Freezing_layer_Resnet18WithCCSAM(num_classes=5)\n",
    "model=Freezing_layer_Resnet18WithCCSAM1(num_classes=5)\n",
    "#print(\"this model is Freezing_layer_Resnet18 with Combination of channel Attention and Spatial Attention Mechanism\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91365b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9024d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a6a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d6253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
