{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import tqdm\n",
    "import pdb\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import os.path as osp\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models\n",
    "from functools import partial\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.backends import cudnn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import DataPreProccessing_1GA\n",
    "\n",
    "from model.baseline_Inception3 import my_InceptionV3\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=Pre_ResNet18Model1(num_classes=5)\n",
    "model=my_InceptionV3(num_classes=5)\n",
    "#model=resnet18_ccsam(num_classes=5)\n",
    "#model=ccsam_inception_v3(num_classes=5)\n",
    "#model = Freezing_layer_Resnet18WithCCSAM1(num_classes=num_classes, pretrained=True)\n",
    "#model = model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of model parameters\n",
    "print('Total Number of model parameters: {}'.format(\n",
    "    sum([p.data.nelement() for p in model.parameters()])))\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "num_non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "\n",
    "print(\"Number of trainable parameters:\", num_trainable_params)\n",
    "print(\"Number of non-trainable parameters:\", num_non_trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python DataPreProccessing_1GA.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "train_loader,valid_loader, TestLoader = DataPreProccessing_1GA.preproccessing()\n",
    "# Define the class labels\n",
    "class_labels = ['FMD', 'KCD', 'LD', 'RWD', 'WD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0816, 0.7364, 0.5701, 0.6013, 0.9144],\n",
      "        [0.3087, 0.2494, 0.4809, 0.3605, 0.9759],\n",
      "        [0.4387, 0.0420, 0.6295, 0.9257, 0.7012],\n",
      "        [0.7401, 0.5881, 0.3205, 0.8118, 0.5745]])\n",
      "tensor([1, 2, 3, 4])\n",
      "Total loss for this batch: 1.51481032371521\n"
     ]
    }
   ],
   "source": [
    "#For this example, we'll be using a cross-entropy loss. For demonstration purposes, we'll create batches of dummy output and label values, run them through the loss function, and examine the result.\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 5\n",
    "# Represents the model's confidence in each of the 5 classes for a given input\n",
    "#dummy_outputs = torch.rand(4, 5)\n",
    "# Represents the correct class among the 5 being tested\n",
    "#class_labels = torch.tensor([1, 2, 3,4])\n",
    "    \n",
    "#print(dummy_outputs)\n",
    "#print(class_labels)\n",
    "\n",
    "#loss = criterion(dummy_outputs, class_labels)\n",
    "#print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tensorboard writer\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "#filename = 'Pre_ResNet18Model1'\n",
    "filename = 'my_InceptionV3'\n",
    "#filename = 'resnet18_ccsam'\n",
    "#filename = 'ccsam_inception_v3'\n",
    "#filename = 'Freezing_layer_Resnet18WithCCSAM1'\n",
    "log_dir = 'D:\\jupyter notebook\\by_my_code\\by_my_code\\Results_log\\logsOf_first_GA/'\n",
    "#log_dir = 'E:/jupyter notebook/my_trying_fie/All_In_One/by_my_code/Results_log/logsOf_first_GA/'\n",
    "#log_dir = 'E:/jupyter notebook/my_trying_fie/All_In_One/by_my_code/Results_log/logsOf_first_GA/'\n",
    "#log_dir = 'E:/jupyter notebook/my_trying_fie/All_In_One/by_my_code/Results_log/logsOf_first_GA/'\n",
    "#log_dir = 'E:/jupyter notebook/my_trying_fie/All_In_One/by_my_code/Results_log/logsOf_first_GA/'\n",
    "saved_model_path=\"E:/jupyter notebook/my_trying_fie/All_In_One/by_my_code/saved_model_code/\"\n",
    "writer = SummaryWriter(log_dir + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "best_vloss = 0.7\n",
    "\n",
    "epoch_number=30\n",
    "# calculate validation loss and accuracy\n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies=[]\n",
    "for epoch in range(epoch_number):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # calculate training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "         # calculate training loss\n",
    "        avg_trainLoss=running_loss / len(train_loader.dataset)\n",
    "        avg_trainAccuracy= 100 * correct / total\n",
    "    model.eval()\n",
    "    #num_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(valid_loader):\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "        avg_valLoss = val_loss / val_total\n",
    "        avg_Val_Accuracy = 100 * val_correct / val_total\n",
    "   # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "        global_step = epoch * len(train_loader) + i\n",
    "        writer.add_scalars('Training vs. Validation Loss', {'Training Loss': loss.item(),\n",
    "                                    'Validation Loss': avg_valLoss}, epoch)\n",
    "        writer.add_scalars('Training vs. Validation Accuracy', {'Training Accuracy': avg_trainAccuracy,\n",
    "                                    'Validation Accuracy': avg_Val_Accuracy}, epoch)\n",
    "        \n",
    "        #Close tensorboard writer\n",
    "        writer.close()\n",
    "    print('Epoch %d: Training Loss: %.3f -- Training Accuracy: %.3f%%  -- Validation Loss: %.3f  -- Validation Accuracy: %.3f%%' %\n",
    "          (epoch + 1, avg_trainLoss, avg_trainAccuracy, avg_valLoss, avg_Val_Accuracy))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_valLoss < best_vloss:\n",
    "        best_vloss = avg_valLoss\n",
    "        model_path = os.path.join(saved_model_path, filename + '.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    epoch_number += 1\n",
    "\n",
    "plt.plot(loss.item(), label='Training loss')\n",
    "plt.plot(avg_valLoss, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(avg_trainAccuracy, label='train_Accuracy')\n",
    "plt.plot(avg_Val_Accuracy, label='val_Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "plt.plot(avg_trainAccuracy, label='train_Accuracy')\n",
    "plt.plot(avg_Val_Accuracy, label='val_Accuracy')\n",
    "plt.plot(loss.item(), label='Training loss')\n",
    "plt.plot(avg_valLoss, label='Validation loss')\n",
    "plt.ylabel('accuracy vs loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,precision_recall_fscore_support\n",
    "\n",
    "model_path = ('E:/jupyter notebook/my_trying_fie/All_In_One/by_my_code/saved_model_code/{filename}' '.pth')\n",
    "# Load saved model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in TestLoader:\n",
    "        data=data \n",
    "        labels =  labels\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Load saved model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define empty arrays for storing true labels and predicted labels\n",
    "true_labels = np.array([])\n",
    "pred_labels = np.array([])\n",
    "\n",
    "# Define empty arrays for storing loss and accuracy\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Evaluate model on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, labels in TestLoader:\n",
    "        data = data\n",
    "        labels = labels\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Get predictions and calculate accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        true_labels = np.append(true_labels, labels.cpu().numpy())\n",
    "        pred_labels = np.append(pred_labels, preds.cpu().numpy())\n",
    "        accuracy = accuracy_score(true_labels, pred_labels) * 100\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, pred_labels)\n",
    "# Normalize confusion matrix to percentages\n",
    "conf_mat_pct = 100 * conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Print confusion matrix\n",
    "print('Confusion matrix:')\n",
    "print(conf_mat_pct)\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(conf_mat_pct, cmap='Blues')\n",
    "\n",
    "# Add color bar\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(class_labels)))\n",
    "ax.set_yticks(np.arange(len(class_labels)))\n",
    "ax.set_xticklabels(class_labels)\n",
    "ax.set_yticklabels(class_labels)\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "\n",
    "# Rotate the tick labels and set their alignment\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "# Loop over data dimensions and create text annotations\n",
    "for i in range(len(class_labels)):\n",
    "    for j in range(len(class_labels)):\n",
    "        ax.text(j, i, format(conf_mat_pct[i, j], '.2f') + '%',\n",
    "                ha='center', va='center', color='white' if conf_mat[i, j] > conf_mat.max() / 2 else 'black')\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Confusion matrix')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "# classification report\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "# accuracy score\n",
    "acc = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "# precision, recall, f1-score, support\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_path = ('E:/jupyter notebook/my_trying_fie/All_In_One/by_my_code/saved_model_code/{filename}' '.pth')\n",
    "# Load saved model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Load single test image and preprocess it\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "img_path = \"E:/jupyter notebook/my_trying_fie/All_In_One/DatasetContainer/Processed_10000_FirstGA_other/test/Foot_mouth_disease/FMD11 (34).jpg\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0., 0., 0.],\n",
    "                         std=[1./255, 1./255, 1./255])\n",
    "])\n",
    "\n",
    "img = Image.open(img_path)\n",
    "img_tensor = transform(img)\n",
    "img_tensor = img_tensor.unsqueeze(0) # add batch dimension\n",
    "\n",
    "# Test model on single image\n",
    "with torch.no_grad():\n",
    "    outputs = model(img_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted class: ', predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
